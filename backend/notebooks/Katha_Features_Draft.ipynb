{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Katha: Smart Cultural Storyteller\n",
                "## Project Notebook: Design, Architecture, and Roadmap\n",
                "\n",
                "---\n",
                "\n",
                "## 1. Introduction\n",
                "\n",
                "**Katha** is an AI-powered cultural storytelling platform that revitalizes ancient Indian epics such as the **Ramayana** and **Mahabharata** for modern audiences. The platform blends cultural authenticity with AI-driven multimedia to create immersive, interactive reading experiences across text, audio, visuals, and maps.\n",
                "\n",
                "This notebook documents:\n",
                "* Current implemented features\n",
                "* System architecture\n",
                "* Planned enhancements\n",
                "* Draft technical logic for upcoming AI modules"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Problem Statement\n",
                "\n",
                "Traditional access to Indian epics faces several challenges:\n",
                "* **Static text formats** reduce engagement for younger audiences accustomed to rich media.\n",
                "* **Language barriers** (archaic English or Sanskrit) limit accessibility.\n",
                "* **Lack of spatial context** makes it hard to visualize journeys (e.g., Rama's path from Ayodhya to Lanka).\n",
                "* **Minimal interactivity** leads to passive consumption rather than active exploration.\n",
                "\n",
                "Katha addresses these by combining **AI narration**, **dynamic visualization**, **interactive maps**, and **cultural design**."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Core Objectives\n",
                "\n",
                "1. **Preserve Cultural Authenticity**: Honor the source material while modernizing its presentation.\n",
                "2. **Enhance Engagement**: Use multimedia (visuals, audio) and gamification to keep users reading.\n",
                "3. **Ensure Accessibility**: Provide multi-lingual support and easy-to-read interfaces.\n",
                "4. **Scalable Architecture**: Build a system where AI content generation (audio/video) can be automated."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Current Implementation (Deployment-Ready)\n",
                "\n",
                "The following features are fully implemented and functional in the v1.0 release:\n",
                "\n",
                "### 4.1 Smart Chapter Reader\n",
                "* Clean, immersive reading UI with simplified navigation.\n",
                "* Ambient background themes that adapt to the story's mood.\n",
                "* Adjustable text rendering for optimal readability.\n",
                "\n",
                "### 4.2 AI Audiobooks\n",
                "* Integrated Text-to-Speech (TTS) narration.\n",
                "* Scene-by-scene audio playback.\n",
                "* (In-Progress) Background sound layering for immersion.\n",
                "\n",
                "### 4.3 Fast Visuals (Static)\n",
                "* Instant AI-generated scene illustrations using lower-latency models.\n",
                "* Served immediately to users to provide visual context.\n",
                "* Acts as a placeholder for the upcoming Cinematic Video Reels.\n",
                "\n",
                "### 4.4 Interactive Epic Map\n",
                "* Geographic visualization of epic events.\n",
                "* Clickable locations (e.g., Ayodhya, Janakpur, Lanka, Kurukshetra).\n",
                "* Content linking: Clicking a map marker opens the related chapter.\n",
                "\n",
                "### 4.5 Gamification Engine\n",
                "* **XP System**: Users earn Experience Points for reading and exploring.\n",
                "* **Streaks**: Daily reading tracking.\n",
                "* **Badges**: Unlockable achievements like \"Scholar\", \"Devotee\", and \"Explorer\".\n",
                "\n",
                "### 4.6 Authentication System\n",
                "* Secure Login and Registration flows.\n",
                "* User profile management.\n",
                "* Persistent reading history across devices."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. System Architecture Overview\n",
                "\n",
                "The Katha platform uses a modern full-stack architecture:\n",
                "\n",
                "### 5.1 High-Level Components\n",
                "\n",
                "1.  **Frontend (React/Vite)**\n",
                "    *   **Reader UI**: The core reading experience.\n",
                "    *   **Visuals & Map**: Interactive components using Leaflet/Mapbox and standard video players.\n",
                "    *   **Gamification**: UI elements for badges and progress bars.\n",
                "\n",
                "2.  **Backend (FastAPI/Python)**\n",
                "    *   **User Management**: Auth, profiles, progress tracking.\n",
                "    *   **Content Delivery**: Serving chapters, scenes, and media assets.\n",
                "    *   **AI Orchestration**: Managing request queues for image/audio/video generation.\n",
                "\n",
                "3.  **AI Services (External APIs)**\n",
                "    *   **Text-to-Speech**: ElevenLabs / EdgeTTS.\n",
                "    *   **Image Generation**: Pollinations.ai / Stability AI.\n",
                "    *   **Video Generation (Planned)**: SVD / Runway.\n",
                "    *   **Translation (Planned)**: DeepL / Google Translate API.\n",
                "\n",
                "4.  **Database**\n",
                "    *   **SQLModel (SQLite/PostgreSQL)**: Stores Users, Stories, Chapters, Scenes, and various mappings."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Upcoming Features (Phase 2)\n",
                "\n",
                "The next phase focuses on high-fidelity media production and linguistic inclusivity."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6.1 Cinematic Video Reel Generation\n",
                "\n",
                "**Goal**: Replace static scene visuals with short, high-quality cinematic video reels to increase immersion.\n",
                "\n",
                "**Planned Capabilities**:\n",
                "*   **Model Integration**: Stable Video Diffusion (SVD), Runway, or Pika.\n",
                "*   **Aspect Ratio**: 9:16 (Vertical video, mobile-first design).\n",
                "*   **Duration**: 4–6 seconds looping clips.\n",
                "*   **Pipeline**: Automated prompt-to-video workflow.\n",
                "\n",
                "#### Draft Logic for Video Generation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import time\n",
                "from typing import Optional\n",
                "\n",
                "class VideoGenerationService:\n",
                "    \"\"\"\n",
                "    Mock service to orchestrate High-Fidelity Video Generation.\n",
                "    Integrates with models like SVD or external APIs.\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, model_name=\"stable-video-diffusion\"):\n",
                "        self.model_name = model_name\n",
                "\n",
                "    def enhance_prompt(self, base_prompt: str) -> str:\n",
                "        \"\"\"\n",
                "        Adds cinematic keywords to ensure consistent high-quality output.\n",
                "        \"\"\"\n",
                "        modifiers = [\n",
                "            \"cinematic\",\n",
                "            \"slow pan camera movement\",\n",
                "            \"dramatic lighting\",\n",
                "            \"4k resolution\",\n",
                "            \"highly detailed\",\n",
                "            \"ancient india atmosphere\"\n",
                "        ]\n",
                "        return f\"{base_prompt}, {', '.join(modifiers)}\"\n",
                "\n",
                "    def generate_reel(self, scene_id: int, prompt: str, duration: int = 4) -> str:\n",
                "        \"\"\"\n",
                "        Generates a video reel for a specific scene.\n",
                "        \"\"\"\n",
                "        print(f\"[VideoService] Processing Scene {scene_id} using {self.model_name}...\")\n",
                "        \n",
                "        # 1. Enhance Prompt\n",
                "        final_prompt = self.enhance_prompt(prompt)\n",
                "        print(f\"[VideoService] Enhanced Prompt: '{final_prompt}'\")\n",
                "\n",
                "        # 2. Call AI Model API (Simulated)\n",
                "        # Replace with actual API call: e.g., client.text_to_video(...)\n",
                "        print(f\"[VideoService] Sending request to {self.model_name} API...\")\n",
                "        time.sleep(1) # Simulating API latency\n",
                "        \n",
                "        # 3. Process Result\n",
                "        # Ideally, we would download the video, optimize it to WebP/MP4, and upload to storage.\n",
                "        generated_url = f\"https://katha-storage.s3.amazonaws.com/reels/scene_{scene_id}_hq.mp4\"\n",
                "        \n",
                "        print(f\"[VideoService] Generation Complete: {generated_url}\")\n",
                "        return generated_url\n",
                "\n",
                "# Example Usage\n",
                "video_service = VideoGenerationService(model_name=\"SVD-XT-1.1\")\n",
                "reel_url = video_service.generate_reel(\n",
                "    scene_id=101,\n",
                "    prompt=\"A golden chariot flying through gathering storm clouds\"\n",
                ")\n",
                "print(f\"Result: {reel_url}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6.2 Multi-Lingual Support (Hindi & Sanskrit)\n",
                "\n",
                "**Goal**: Enable users to experience epics in their original and vernacular languages while maintaining narrative accuracy.\n",
                "\n",
                "**Planned Capabilities**:\n",
                "*   **Language Toggle**: Switch between English, Hindi, and Sanskrit on the fly.\n",
                "*   **Devanagari Rendering**: Proper font support for Indian scripts.\n",
                "*   **Localized AI Narration**: Using culturally appropriate voice models for each language.\n",
                "\n",
                "#### Draft Logic for Translation & Narration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class LocalizationService:\n",
                "    \"\"\"\n",
                "    Handles translation and localized audio generation.\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self):\n",
                "        self.voice_map = {\n",
                "            \"hindi\": \"hindi_narrator_male_deep\",\n",
                "            \"sanskrit\": \"sanskrit_scholar_priest\",\n",
                "            \"english\": \"english_storyteller_soothing\"\n",
                "        }\n",
                "\n",
                "    def translate_text(self, text: str, target_lang: str) -> str:\n",
                "        \"\"\"\n",
                "        Calls an external Neural Machine Translation service.\n",
                "        \"\"\"\n",
                "        # Mock Translation Logic\n",
                "        print(f\"[LocService] Translating text to {target_lang}...\")\n",
                "        if target_lang == \"hindi\":\n",
                "            return \"(Hindi Translation Placeholder) प्राचीन काल में...\"\n",
                "        elif target_lang == \"sanskrit\":\n",
                "            return \"(Sanskrit Translation Placeholder) पुराकाले...\"\n",
                "        return text\n",
                "\n",
                "    def generate_localized_asset(self, scene_id: int, original_text: str, target_lang: str):\n",
                "        \"\"\"\n",
                "        Orchestrates the full localization pipeline for a scene.\n",
                "        \"\"\"\n",
                "        # 1. Translate\n",
                "        translated_text = self.translate_text(original_text, target_lang)\n",
                "        \n",
                "        # 2. Select Voice\n",
                "        voice_id = self.voice_map.get(target_lang, \"default_voice\")\n",
                "        print(f\"[LocService] Selected Voice ID: {voice_id}\")\n",
                "        \n",
                "        # 3. Generate Audio (Simulated TTS Call)\n",
                "        print(f\"[LocService] Generating Audio via TTS...\")\n",
                "        audio_url = f\"/static/audio/{target_lang}/scene_{scene_id}.mp3\"\n",
                "        \n",
                "        return {\n",
                "            \"language\": target_lang,\n",
                "            \"text\": translated_text,\n",
                "            \"audio_url\": audio_url,\n",
                "            \"voice_used\": voice_id\n",
                "        }\n",
                "\n",
                "# Example Usage\n",
                "loc_service = LocalizationService()\n",
                "asset_hindi = loc_service.generate_localized_asset(\n",
                "    scene_id=42,\n",
                "    original_text=\"Long ago, in the city of Ayodhya...\",\n",
                "    target_lang=\"hindi\"\n",
                ")\n",
                "print(asset_hindi)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Ethical and Cultural Considerations\n",
                "\n",
                "When integrating AI with sacred or culturally significant texts, we adhere to strict guidelines:\n",
                "1.  **No Distortion**: The AI should not alter the core narrative or moral lessons of the original scriptures.\n",
                "2.  **Visual Respect**: Generated imagery must be respectful of traditional iconographies (e.g., correct attire, symbols).\n",
                "3.  **Educational Intent**: Users are informed that AI features are for immersion and educational purposes, bridging the gap to original texts."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Future Extensions\n",
                "\n",
                "Beyond the current implementation and verified next steps, the long-term vision includes:\n",
                "*   **Personalized Paths**: Story branches based on user choices (where applicable in folklore).\n",
                "*   **AI Oracle (Rishi)**: A chatbot interface to ask questions about characters and dharma.\n",
                "*   **Classroom Mode**: Tools for teachers to track student progress and assign chapters.\n",
                "*   **Offline Support**: Full PWA capabilities for reading without internet."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Conclusion\n",
                "\n",
                "**Katha** stands at the intersection of heritage and technology. The current deployment serves as a robust foundation—providing a fast, interactive, and gamified reading experience. With the upcoming integration of cinematic video reels and multi-lingual support, Katha aims to become the definitive platform for experiencing the timeless wisdom of Indian epics."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
